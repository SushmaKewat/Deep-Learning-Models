{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b6bcd4",
   "metadata": {},
   "source": [
    "## Handwritten Digits Classification\n",
    "### Using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0bbfd",
   "metadata": {},
   "source": [
    "We first create a basic convnet which is a stack of `Conv2D` and `MaxPooling2D` layers.\n",
    "\n",
    "A CNN takes as input tensors of shape `(image_height, image_width, image_channels)`.\n",
    "\n",
    "For our network we will configure the inputs of size `(28, 28, 1)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cdb734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55744 (217.75 KB)\n",
      "Trainable params: 55744 (217.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c29d95",
   "metadata": {},
   "source": [
    "Now we need to feed the last ouput tensor into a densly-connected classifier network, like a stack of Dense layers.\n",
    "\n",
    "These classifiers process vectors that are 1D, whereas our current output is 3D tensor.\n",
    "\n",
    "Therefore, we will have to flatten our 3D outputs to 1D, and then add few Dense layers on top.\n",
    "\n",
    "As we are going to do 10-way classification, we use a final layer with 10 outputs and a softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409bf976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a94499",
   "metadata": {},
   "source": [
    "### Use CNN on MNIST Digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c8884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32')/255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e116343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 2/8\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0096 - accuracy: 0.9970\n",
      "Epoch 3/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0077 - accuracy: 0.9976\n",
      "Epoch 4/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 5/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0049 - accuracy: 0.9988\n",
      "Epoch 6/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 7/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 8/8\n",
      "938/938 [==============================] - 12s 13ms/step - loss: 0.0037 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20c19f2bdc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs = 8, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f36c83",
   "metadata": {},
   "source": [
    "We reached an accuracy of `0.9987( i.e, 99.87% )` on the training data. Now check the model's performance on testing data too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26c13c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0408 - accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9922000169754028"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b4473",
   "metadata": {},
   "source": [
    "The test accuracy turns out to be `99.22%`, which is more than the accuracy of multilayer perceptron on test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
